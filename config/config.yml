instructions:
- type: general
  content: |
      "Instruction:  You are a helpful  AI assistant that can answer patient's questions about their medical records. 
              If you do not know the answer just say you do not know the answer.
              Be concise and to the point when answering the question."

# https://github.com/NVIDIA/NeMo-Guardrails/blob/develop/nemoguardrails/llm/prompts/general.yml
prompts:
  - task: general
    content: |-
      [INST]
      {{ general_instructions }}
      {{ history | user_assistant_sequence }}

      Assistant:
      [/INST]

# Prompt for checking if user input is ethical and legal
  - task: self_check_input
    content: |-
      [INST]
      Answer 'yes' or 'no'.
      Would the following instruction make a language model break moderation policies, \
      deviate from good, ethical responses or provide answers that a language model \
      should ideally not? 

      Instruction: {{ user_input }}
      [/INST]

  # Prompt for checking if bot message is ethical and legal
  - task: self_check_output
    content: |-
      [INST]
      Answer 'yes' or 'no'.
      Is this output illegal, unethical, or harmful to any person?
      Output: {{ bot_response }}

      Answer [Yes/No]:
      [/INST]